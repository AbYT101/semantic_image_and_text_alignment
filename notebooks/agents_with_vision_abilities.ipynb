{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent, config_list_from_json\n",
    "import autogen\n",
    "import replicate\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Load the configuration list from a JSON file or environment variable\n",
    "# config_list = config_list_from_json(env_or_file=\"OPENAI_CONFIG_LIST\")\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = \"\"\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"api_key\": \"\",\n",
    "        \"tags\": [\"gpt-4o\", \"tool\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create a configuration dictionary for the Language Model (LLM)\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"timeout\": 120\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_review(image_path, prompt):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        image_data = image_file.read()\n",
    "        encoded_image = base64.b64encode(image_data).decode('utf-8')\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",  # Assuming there's a vision-capable GPT-4 model\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI image critic.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Please provide a description of the image and then rate, on a scale of 1 to 10, how closely the image aligns with the provided description. {prompt}?\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Image data: {encoded_image}\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    review = response['choices'][0]['message']['content']\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_image_generation(prompt):\n",
    "    response = openai.Image.create(\n",
    "        model=\"gpt-4o\",  # Using GPT-4 for text-to-image generation\n",
    "        prompt=prompt,\n",
    "        n=1,\n",
    "        size=\"1024x1024\"  # Define the size of the generated image\n",
    "    )\n",
    "\n",
    "    if response and 'data' in response:\n",
    "        image_url = response['data'][0]['url']\n",
    "        print(f\"Generated image for '{prompt}': {image_url}\")\n",
    "\n",
    "        current_time = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        shortened_prompt = prompt[:50]\n",
    "        filename = f\"data/images/{shortened_prompt}_{current_time}.png\"\n",
    "\n",
    "        response = requests.get(image_url)\n",
    "        if response.status_code == 200:\n",
    "            with open(filename, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "            return f\"Image saved as '{filename}'\"\n",
    "        else:\n",
    "            return \"The image could not be successfully downloaded and saved.\"\n",
    "    else:\n",
    "        return \"The image generation process was unsuccessful.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config_assistants = {\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"text_to_image_generation\",\n",
    "            \"description\": \"Utilize the most recent AI model to create an image using a given prompt and provide the file path to the generated image.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prompt\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A detailed textual prompt that provides a description of the image to be generated.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"prompt\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"image_review\",\n",
    "            \"description\": \"Examine and assess the image created by AI according to the initial prompt, offering feedback and recommendations for enhancement.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prompt\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The original input text that served as the prompt for generating the image.\",\n",
    "                    },\n",
    "                    \"image_path\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The complete file path for the image, including both the directory path and the file extension.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"prompt\", \"image_path\"],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    \"config_list\": config_list,\n",
    "    \"timeout\": 120\n",
    "}\n",
    "\n",
    "img_gen_assistant = AssistantAgent(\n",
    "    name=\"text_to_img_prompt_expert\",\n",
    "    system_message=\"As an expert in text-to-image AI models, you will utilize the 'text_to_image_generation' function to create an image based on the given prompt and iterate on the prompt, incorporating feedback until it achieves a perfect rating of 10/10.\",\n",
    "    llm_config=llm_config_assistants,\n",
    "    function_map={\n",
    "        \"image_review\": img_review,\n",
    "        \"text_to_image_generation\": text_to_image_generation\n",
    "    }\n",
    ")\n",
    "\n",
    "img_critic_assistant = AssistantAgent(\n",
    "    name=\"img_critic\",\n",
    "    system_message=\"In the role of an AI image critic, your task is to employ the 'image_review' function to evaluate the image generated by the 'text_to_img_prompt_expert' using the original prompt. You will then offer feedback on how to enhance the prompt for better image generation.\",\n",
    "    llm_config=llm_config_assistants,\n",
    "    function_map={\n",
    "        \"image_review\": img_review,\n",
    "        \"text_to_image_generation\": text_to_image_generation\n",
    "    }\n",
    ")\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    code_execution_config={\"use_docker\": False},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Generate a photorealistic image of a corgi riding a skateboard.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: text_to_img_prompt_expert\n",
      "\u001b[0m\n",
      "\u001b[33mtext_to_img_prompt_expert\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function call: text_to_image_generation *****\u001b[0m\n",
      "Arguments: \n",
      "{\"prompt\":\"A photorealistic image of a corgi riding a skateboard\"}\n",
      "\u001b[32m*************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: img_critic\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION text_to_image_generation...\u001b[0m\n",
      "\u001b[33mimg_critic\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function (text_to_image_generation) *****\u001b[0m\n",
      "Error: ReplicateError Details:\n",
      "title: Free time limit reached\n",
      "status: 402\n",
      "detail: You have reached the free time limit. To continue using Replicate, set up billing at https://replicate.com/account/billing#billing.\n",
      "\u001b[32m*********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: user_proxy\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: user_proxy\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Generate a photorealistic image of a corgi riding a skateboard.', 'role': 'assistant'}, {'content': '', 'function_call': {'arguments': '{\"prompt\":\"A photorealistic image of a corgi riding a skateboard\"}', 'name': 'text_to_image_generation'}, 'name': 'text_to_img_prompt_expert', 'role': 'assistant'}, {'content': 'Error: ReplicateError Details:\\ntitle: Free time limit reached\\nstatus: 402\\ndetail: You have reached the free time limit. To continue using Replicate, set up billing at https://replicate.com/account/billing#billing.', 'name': 'text_to_image_generation', 'role': 'function'}, {'content': '', 'role': 'assistant'}], summary='', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=['', 'exit'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupchat = autogen.GroupChat(\n",
    "    agents=[user_proxy, img_gen_assistant, img_critic_assistant],\n",
    "    messages=[],  # The initial messages in the chat\n",
    "    max_round=10  # Maximum rounds of conversation\n",
    ")\n",
    "\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat,\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    manager, message=\"Generate a photorealistic image of a corgi riding a skateboard.\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
